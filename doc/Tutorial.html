<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>mmetrics</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">mmetrics</h1>



<p>The <code>mmetrics</code> package contains functions necessary to
assess classification performance for statistical modelings, in
particular, when encountering multi-class classification problems or
different types of averaging methods of metric computation are of
interest. This vignette compares <code>mmetrics</code> functions to
their R equivalents in <code>caret</code>.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>())</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="fu">library</span>(mmetrics)</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="fu">library</span>(NHANES)</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="co">#&gt; randomForest 4.7-1.1</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co">#&gt; Type rfNews() to see new features/changes/bug fixes.</span></span></code></pre></div>
<p>There are a range of classification metric computation customization
options available for users of the package. To demonstrate this
function, the NHANES data from <code>NHANES</code> will be used.</p>
<p>In particular, we formulate our problem as building predictive
modeling based on logistic regression model. The goal is to predict
<code>Depressed</code> (categorical variable) from
<code>SleepHrsNight</code>, <code>BMI</code>,<code>Poverty</code> and
<code>PhysActive</code>, as well as demographic variable:
<code>Age</code> and <code>Gender</code>.</p>
<div id="model-fitting" class="section level2">
<h2>Model fitting</h2>
<p>First we filter out participants’ with NA value and partition the
dataset into training and testing.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># filter out records with NA value</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>df <span class="ot">&lt;-</span> NHANES[,<span class="fu">c</span>(<span class="st">&quot;Depressed&quot;</span>, <span class="st">&quot;SleepHrsNight&quot;</span>, <span class="st">&quot;BMI&quot;</span>, <span class="st">&quot;PhysActive&quot;</span>, <span class="st">&quot;Poverty&quot;</span>, <span class="st">&quot;Age&quot;</span>, <span class="st">&quot;Gender&quot;</span>)]</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>df <span class="ot">&lt;-</span> df[<span class="fu">apply</span>(<span class="sc">!</span><span class="fu">is.na</span>(df), <span class="dv">1</span>, all),]</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="co"># split train and test set</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">345</span>)</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(df)</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>train_id <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>n, <span class="fu">floor</span>(<span class="fl">0.8</span><span class="sc">*</span>n))</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>test_id <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">1</span>, n)[<span class="sc">!</span>(<span class="fu">seq</span>(<span class="dv">1</span>,n) <span class="sc">%in%</span> train_id)]</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>train_df <span class="ot">&lt;-</span> df[train_id, ]</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>test_df <span class="ot">&lt;-</span> df[test_id, <span class="dv">2</span><span class="sc">:</span><span class="fu">ncol</span>(df)]</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a>target <span class="ot">&lt;-</span> (df[test_id, ]<span class="sc">$</span>Depressed)</span></code></pre></div>
<p>Often times, we are interested in fitting more than one model and
compare their performance in hope of obtaining a more predictive model.
Hence, suppose we have two different random forest models under
different random seed for a same classification task.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">345</span>)</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(Depressed<span class="sc">~</span>., train_df, <span class="at">ntree=</span><span class="dv">10</span>, <span class="at">replace=</span><span class="cn">FALSE</span>)</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>preds_prob1 <span class="ot">&lt;-</span> (<span class="fu">predict</span>(model1, test_df, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>))</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>preds1 <span class="ot">&lt;-</span> (<span class="fu">predict</span>(model1, test_df))</span></code></pre></div>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">345</span>)</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(Depressed<span class="sc">~</span>., train_df, <span class="at">ntree=</span><span class="dv">200</span>,<span class="at">replace=</span><span class="cn">FALSE</span>)</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>preds_prob2 <span class="ot">&lt;-</span> (<span class="fu">predict</span>(model2, test_df, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>))</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>preds2 <span class="ot">&lt;-</span> (<span class="fu">predict</span>(model2, test_df))</span></code></pre></div>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="fu">rm</span>(model1, model2)</span></code></pre></div>
</div>
<div id="model-performance-assessment" class="section level2">
<h2>Model performance assessment</h2>
<div id="accuracy" class="section level3">
<h3>Accuracy</h3>
<p>To calculate classification accuracy, if there is a particular class
is of interest, then <code>binary_acc</code> can be applied to calculate
class-specific accuracy scores.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>e_s1 <span class="ot">=</span> <span class="fu">binary_acc</span>(preds1<span class="sc">==</span><span class="st">&quot;Most&quot;</span>, target<span class="sc">==</span><span class="st">&quot;Most&quot;</span>); e_r1 <span class="ot">=</span> <span class="fu">binary_acc</span>(preds2<span class="sc">==</span><span class="st">&quot;Most&quot;</span>, target<span class="sc">==</span><span class="st">&quot;Most&quot;</span>)</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>e_s2 <span class="ot">=</span> <span class="fu">binary_acc</span>(preds1<span class="sc">==</span><span class="st">&quot;Most&quot;</span>, target<span class="sc">==</span><span class="st">&quot;Several&quot;</span>); e_r2 <span class="ot">=</span> <span class="fu">binary_acc</span>(preds2<span class="sc">==</span><span class="st">&quot;Most&quot;</span>, target<span class="sc">==</span><span class="st">&quot;Several&quot;</span>)</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>e_s3 <span class="ot">=</span> <span class="fu">binary_acc</span>(preds1<span class="sc">==</span><span class="st">&quot;Most&quot;</span>, target<span class="sc">==</span><span class="st">&quot;None&quot;</span>); e_r3 <span class="ot">=</span> <span class="fu">binary_acc</span>(preds2<span class="sc">==</span><span class="st">&quot;Most&quot;</span>, target<span class="sc">==</span><span class="st">&quot;None&quot;</span>)</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">model1 =</span> <span class="fu">c</span>(e_s1, e_s2, e_s3), <span class="at">model2 =</span> <span class="fu">c</span>(e_r1, e_r2, e_r3), <span class="at">row.names =</span> <span class="fu">c</span>(<span class="st">&quot;Most&quot;</span>, <span class="st">&quot;Several&quot;</span>, <span class="st">&quot;None&quot;</span>))</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="co">#&gt;            model1    model2</span></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="co">#&gt; Most    0.9595142 0.9651822</span></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a><span class="co">#&gt; Several 0.8348178 0.8291498</span></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a><span class="co">#&gt; None    0.1854251 0.1829960</span></span></code></pre></div>
<p>To obtain an overall performance regarding classification accuracy,
<code>multiclass-acc</code> offers two options of averaging
classification performance across different class, where
<code>micro</code> computes global average and <code>macro</code>
computes averaged accuracies of all labels. When the ground-truth
classes of target values are imbalanced, analyst should consider using
<code>macro</code> average to mitigate bias introduced by dominant
class. Note that in multiclass accuracy calculation, one-versus-the-rest
does not apply there anymore.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="fu">table</span>(target)</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="co">#&gt; target</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="co">#&gt;    None Several    Most </span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="co">#&gt;     983     185      67</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>mic_e_s <span class="ot">=</span> <span class="fu">multiclass_acc</span>(preds1, target)</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>mac_e_s <span class="ot">=</span> <span class="fu">multiclass_acc</span>(preds1, target, <span class="at">average =</span> <span class="st">&quot;macro&quot;</span>)</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a>mic_e_r <span class="ot">=</span> <span class="fu">multiclass_acc</span>(preds2, target)</span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a>mac_e_r <span class="ot">=</span> <span class="fu">multiclass_acc</span>(preds2, target, <span class="at">average =</span> <span class="st">&quot;macro&quot;</span>)</span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">model1 =</span> <span class="fu">c</span>(mic_e_s, mac_e_s), <span class="at">model2 =</span> <span class="fu">c</span>(mic_e_r, mac_e_r), <span class="at">row.names =</span> <span class="fu">c</span>(<span class="st">&quot;Micro Average&quot;</span>, <span class="st">&quot;Macro Average&quot;</span>))</span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a><span class="co">#&gt;                  model1    model2</span></span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a><span class="co">#&gt; Micro Average 0.8680162 0.8753036</span></span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a><span class="co">#&gt; Macro Average 0.5837367 0.6041179</span></span></code></pre></div>
</div>
<div id="confusion-scores" class="section level3">
<h3>Confusion Scores</h3>
<p>To compute the confusion matrices and corresponding scores, we can
use either <code>confusion_scores</code> to obtain binary or
class-specific result, or use <code>multiclass_confusion_scores</code>
to get the contingency table or class-specific confusion matrices.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="do">## class specific</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>mtx1 <span class="ot">=</span> <span class="fu">confusion_scores</span>(preds1<span class="sc">==</span><span class="st">&quot;Most&quot;</span>, target<span class="sc">==</span><span class="st">&quot;Most&quot;</span>)<span class="sc">$</span>matrix</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>mtx2 <span class="ot">=</span> <span class="fu">multiclass_confusion_scores</span>(preds1, target, <span class="at">classtype =</span> <span class="st">&quot;Most&quot;</span>)<span class="sc">$</span>matrix</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="fu">stopifnot</span>(mtx1<span class="sc">==</span>mtx2); mtx1</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="co">#&gt;      [,1] [,2]</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="co">#&gt; [1,]   21    4</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a><span class="co">#&gt; [2,]   46 1164</span></span></code></pre></div>
<p>Or if not specify the class, <code>multiclass_confusion_scores</code>
returns a multiclass contingency table</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="fu">multiclass_confusion_scores</span>(preds1, target)</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a><span class="co">#&gt;          target</span></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="co">#&gt; preds     None Several Most</span></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a><span class="co">#&gt;   None     967      98   40</span></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a><span class="co">#&gt;   Several   15      84    6</span></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a><span class="co">#&gt;   Most       1       3   21</span></span></code></pre></div>
</div>
<div id="precision-scores-and-recall-scores" class="section level3">
<h3>Precision scores and Recall scores</h3>
<p>To figure out how capable the model is in their positively-predicted
cases, <code>binary_precision</code> carries out the computation in
binary classification cases. Predicted probability can also be served as
input with customizable threshold to compute precision score (the same
as accuracy score mentioned before). We demonstrate probability input to
calculate precision score in a one-versus-the-rest sense.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="fu">binary_precision</span>(preds_prob1[,<span class="st">&quot;None&quot;</span>], target<span class="sc">==</span><span class="st">&quot;None&quot;</span>, <span class="at">threshold=</span><span class="fl">0.5</span>)</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="co">#&gt; [1] 0.88117</span></span></code></pre></div>
<p>Model performance in precision can be similar obtained with micro or
macro averaging method.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>mic_p_s <span class="ot">=</span> <span class="fu">multiclass_precision</span>(preds1, target, <span class="at">average =</span> <span class="st">&quot;micro&quot;</span>)</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>mac_p_s <span class="ot">=</span> <span class="fu">multiclass_precision</span>(preds1, target, <span class="at">average =</span> <span class="st">&quot;macro&quot;</span>)</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>mic_p_r <span class="ot">=</span> <span class="fu">multiclass_precision</span>(preds2, target, <span class="at">average =</span> <span class="st">&quot;micro&quot;</span>)</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>mac_p_r <span class="ot">=</span> <span class="fu">multiclass_precision</span>(preds2, target, <span class="at">average =</span> <span class="st">&quot;macro&quot;</span>)</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">model1 =</span> <span class="fu">c</span>(mic_p_s, mac_p_s), <span class="at">model2 =</span> <span class="fu">c</span>(mic_p_r, mac_p_r), <span class="at">row.names =</span> <span class="fu">c</span>(<span class="st">&quot;Micro Average&quot;</span>, <span class="st">&quot;Macro Average&quot;</span>))</span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a><span class="co">#&gt;                  model1    model2</span></span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a><span class="co">#&gt; Micro Average 0.8680162 0.8753036</span></span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a><span class="co">#&gt; Macro Average 0.8383710 0.8998470</span></span></code></pre></div>
<p>Similarly, recall function is designed for measuring whether a model
is capable in picking out positive ground-truth labels, i.e. calculating
the sensitivity of the classification model.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="fu">binary_recall</span>(preds_prob1[,<span class="st">&quot;None&quot;</span>], target<span class="sc">==</span><span class="st">&quot;None&quot;</span>, <span class="at">threshold=</span><span class="fl">0.5</span>)</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="co">#&gt; [1] 0.9806714</span></span></code></pre></div>
<p>Model performances in recall differ when different averaging methods
are used. The lower macro score indicates that the model holds less
predictive power for more prevalent labels, in particular the label
“None” and possibly the label “Several”.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>mic_r_s <span class="ot">=</span> <span class="fu">multiclass_recall</span>(preds1, target, <span class="at">average =</span> <span class="st">&quot;micro&quot;</span>)</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>mac_r_s <span class="ot">=</span> <span class="fu">multiclass_recall</span>(preds1, target, <span class="at">average =</span> <span class="st">&quot;macro&quot;</span>)</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>mic_r_r <span class="ot">=</span> <span class="fu">multiclass_recall</span>(preds2, target, <span class="at">average =</span> <span class="st">&quot;micro&quot;</span>)</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>mac_r_r <span class="ot">=</span> <span class="fu">multiclass_recall</span>(preds2, target, <span class="at">average =</span> <span class="st">&quot;macro&quot;</span>)</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">model1 =</span> <span class="fu">c</span>(mic_r_s, mac_r_s), <span class="at">model2 =</span> <span class="fu">c</span>(mic_r_r, mac_r_r), <span class="at">row.names =</span> <span class="fu">c</span>(<span class="st">&quot;Micro Average&quot;</span>, <span class="st">&quot;Macro Average&quot;</span>))</span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a><span class="co">#&gt;                  model1    model2</span></span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a><span class="co">#&gt; Micro Average 0.8680162 0.8753036</span></span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a><span class="co">#&gt; Macro Average 0.5837367 0.6041179</span></span></code></pre></div>
</div>
</div>
<div id="f1-scores" class="section level2">
<h2>F1 scores</h2>
<p>F1-score as the geometric average for recall score and precision
score, reflects the overall capability of a classification model (mainly
binary, but the concept can also be applied to a multiclass problem) in
classifying each observation to their corresponding class.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="fu">binary_f1</span>(preds_prob1[,<span class="st">&quot;None&quot;</span>], target<span class="sc">==</span><span class="st">&quot;None&quot;</span>, <span class="at">threshold=</span><span class="fl">0.5</span>)</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="co">#&gt; [1] 0.9282619</span></span></code></pre></div>
<p>Compare the result with the one we obtained in the previous section,
we see the f1 score balances both precision and recall scores in terms
of magnitude.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>mic_f_s <span class="ot">=</span> <span class="fu">multiclass_f1</span>(preds1, target, <span class="at">average =</span> <span class="st">&quot;micro&quot;</span>)</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>mac_f_s <span class="ot">=</span> <span class="fu">multiclass_f1</span>(preds1, target, <span class="at">average =</span> <span class="st">&quot;macro&quot;</span>)</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>mic_f_r <span class="ot">=</span> <span class="fu">multiclass_f1</span>(preds2, target, <span class="at">average =</span> <span class="st">&quot;micro&quot;</span>)</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>mac_f_r <span class="ot">=</span> <span class="fu">multiclass_f1</span>(preds2, target, <span class="at">average =</span> <span class="st">&quot;macro&quot;</span>)</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">model1 =</span> <span class="fu">c</span>(mic_f_s, mac_f_s), <span class="at">model2 =</span> <span class="fu">c</span>(mic_f_r, mac_f_r), <span class="at">row.names =</span> <span class="fu">c</span>(<span class="st">&quot;Micro Average&quot;</span>, <span class="st">&quot;Macro Average&quot;</span>))</span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a><span class="co">#&gt;                  model1    model2</span></span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a><span class="co">#&gt; Micro Average 0.8680162 0.8753036</span></span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a><span class="co">#&gt; Macro Average 0.6540258 0.6864798</span></span></code></pre></div>
</div>
<div id="sample-wise-calculation" class="section level2">
<h2>Sample-wise calculation</h2>
<p>In the domain of statistical learning, sample-wise metrics may be of
interest. To enable this feature, requiring
<code>multidim_average</code> to be “samplewise” would be
sufficient.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">345</span>)</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>preds_samplewise <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">sample</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">1</span>, <span class="dv">100</span>, <span class="at">replace =</span> T), <span class="dv">10</span>, <span class="dv">10</span>)</span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>target_samplewise <span class="ot">=</span> <span class="fu">t</span>(preds_samplewise)</span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a><span class="fu">binary_acc</span>(preds_samplewise, target_samplewise, <span class="at">multidim_average =</span> <span class="st">&quot;samplewise&quot;</span>)</span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a><span class="co">#&gt;  [1] 0.5 0.4 0.3 0.4 0.4 0.5 0.4 0.4 0.4 0.7</span></span></code></pre></div>
</div>
<div id="comparison-and-benchmarking" class="section level2">
<h2>Comparison and Benchmarking</h2>
<p>From this simple case, we get the chance of measuring a
classification model’s performance from various levels.</p>
<p>Nevertheless, we realize that there are established r packages
working on a similar set of classification metric function. The goal for
this section is to compare function from <code>mmetrics</code> and
<code>caret</code>.</p>
<p>Note that <code>recall</code> and <code>precision</code> function in
<code>caret</code> support factor input only. As all measurement
functions in <code>mmetrics</code> calls confusion matrix functions, and
that confusion matrix computation from two packages return different
format of output, evaluating <code>mmetrics::accuracy</code>,
<code>mmetrics::precision</code>, <code>mmetrics::recall</code> with
<code>caret</code>’s function can indirectly give us a sufficient sense
of the correctness of <code>mmetrics::confusion_scores</code> function.
Furthermore, <code>caret</code></p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a><span class="co">#&gt; Loading required package: ggplot2</span></span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a><span class="co">#&gt; Attaching package: &#39;ggplot2&#39;</span></span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a><span class="co">#&gt; The following object is masked from &#39;package:randomForest&#39;:</span></span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a><span class="co">#&gt;     margin</span></span>
<span id="cb17-8"><a href="#cb17-8" tabindex="-1"></a><span class="co">#&gt; Loading required package: lattice</span></span>
<span id="cb17-9"><a href="#cb17-9" tabindex="-1"></a><span class="fu">library</span>(bench)</span>
<span id="cb17-10"><a href="#cb17-10" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">345</span>)</span>
<span id="cb17-11"><a href="#cb17-11" tabindex="-1"></a>preds_sim <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">1</span>, <span class="dv">100000</span>, <span class="at">replace =</span> T)</span>
<span id="cb17-12"><a href="#cb17-12" tabindex="-1"></a>preds_sim_fac <span class="ot">=</span> <span class="fu">factor</span>(preds_sim, <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>))</span>
<span id="cb17-13"><a href="#cb17-13" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb17-14"><a href="#cb17-14" tabindex="-1"></a>target_sim <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">1</span>, <span class="dv">100000</span>, <span class="at">replace =</span> T)</span>
<span id="cb17-15"><a href="#cb17-15" tabindex="-1"></a>target_sim_fac <span class="ot">=</span> <span class="fu">factor</span>(target_sim, <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>))</span>
<span id="cb17-16"><a href="#cb17-16" tabindex="-1"></a></span>
<span id="cb17-17"><a href="#cb17-17" tabindex="-1"></a>cfs <span class="ot">=</span> <span class="fu">confusionMatrix</span>(preds_sim_fac, target_sim_fac)</span>
<span id="cb17-18"><a href="#cb17-18" tabindex="-1"></a></span>
<span id="cb17-19"><a href="#cb17-19" tabindex="-1"></a><span class="do">## accuracy</span></span>
<span id="cb17-20"><a href="#cb17-20" tabindex="-1"></a><span class="fu">all.equal</span>(cfs[[<span class="st">&quot;overall&quot;</span>]][[<span class="st">&quot;Accuracy&quot;</span>]], <span class="fu">binary_acc</span>(preds_sim, target_sim))</span>
<span id="cb17-21"><a href="#cb17-21" tabindex="-1"></a><span class="co">#&gt; [1] TRUE</span></span>
<span id="cb17-22"><a href="#cb17-22" tabindex="-1"></a>test.cfs <span class="ot">=</span> <span class="cf">function</span>(){</span>
<span id="cb17-23"><a href="#cb17-23" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb17-24"><a href="#cb17-24" tabindex="-1"></a>    <span class="fu">confusionMatrix</span>(preds_sim_fac, target_sim_fac)[[<span class="st">&quot;overall&quot;</span>]][[<span class="st">&quot;Accuracy&quot;</span>]]</span>
<span id="cb17-25"><a href="#cb17-25" tabindex="-1"></a>  }</span>
<span id="cb17-26"><a href="#cb17-26" tabindex="-1"></a>}</span>
<span id="cb17-27"><a href="#cb17-27" tabindex="-1"></a>test.acc <span class="ot">=</span> <span class="cf">function</span>(){</span>
<span id="cb17-28"><a href="#cb17-28" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb17-29"><a href="#cb17-29" tabindex="-1"></a>    <span class="fu">binary_acc</span>(preds_sim, target_sim)</span>
<span id="cb17-30"><a href="#cb17-30" tabindex="-1"></a>  }</span>
<span id="cb17-31"><a href="#cb17-31" tabindex="-1"></a>}</span>
<span id="cb17-32"><a href="#cb17-32" tabindex="-1"></a><span class="fu">mark</span>(<span class="fu">test.cfs</span>(), <span class="fu">test.acc</span>())</span>
<span id="cb17-33"><a href="#cb17-33" tabindex="-1"></a><span class="co">#&gt; Warning: Some expressions had a GC in every iteration; so filtering is</span></span>
<span id="cb17-34"><a href="#cb17-34" tabindex="-1"></a><span class="co">#&gt; disabled.</span></span>
<span id="cb17-35"><a href="#cb17-35" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 × 6</span></span>
<span id="cb17-36"><a href="#cb17-36" tabindex="-1"></a><span class="co">#&gt;   expression      min   median `itr/sec` mem_alloc `gc/sec`</span></span>
<span id="cb17-37"><a href="#cb17-37" tabindex="-1"></a><span class="co">#&gt;   &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;</span></span>
<span id="cb17-38"><a href="#cb17-38" tabindex="-1"></a><span class="co">#&gt; 1 test.cfs()    811ms    811ms      1.23     477MB     12.3</span></span>
<span id="cb17-39"><a href="#cb17-39" tabindex="-1"></a><span class="co">#&gt; 2 test.acc()    937ms    937ms      1.07     810MB     20.3</span></span></code></pre></div>
<ul>
<li>Accuracy computation from two packages accurately get matched with
each other and they achieve comparable duration time. Nevertheless,
retrieving accuracy information in <code>caret</code> takes up less
run-time memory use. This may attribute to the fact that more
computation options are enabled in <code>binary_accuracy</code>
including multidimensional average option.</li>
</ul>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="do">## precision</span></span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a><span class="fu">all.equal</span>(cfs[[<span class="st">&quot;byClass&quot;</span>]][[<span class="st">&quot;Pos Pred Value&quot;</span>]], <span class="fu">binary_precision</span>(preds_sim, target_sim))</span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a><span class="co">#&gt; [1] TRUE</span></span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a>test.cfs <span class="ot">=</span> <span class="cf">function</span>(){</span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a>    <span class="fu">confusionMatrix</span>(preds_sim_fac, target_sim_fac)[[<span class="st">&quot;byClass&quot;</span>]][[<span class="st">&quot;Pos Pred Value&quot;</span>]]</span>
<span id="cb18-7"><a href="#cb18-7" tabindex="-1"></a>  }</span>
<span id="cb18-8"><a href="#cb18-8" tabindex="-1"></a>}</span>
<span id="cb18-9"><a href="#cb18-9" tabindex="-1"></a>test.precision <span class="ot">=</span> <span class="cf">function</span>(){</span>
<span id="cb18-10"><a href="#cb18-10" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb18-11"><a href="#cb18-11" tabindex="-1"></a>    <span class="fu">binary_precision</span>(preds_sim, target_sim)</span>
<span id="cb18-12"><a href="#cb18-12" tabindex="-1"></a>  }</span>
<span id="cb18-13"><a href="#cb18-13" tabindex="-1"></a>}</span>
<span id="cb18-14"><a href="#cb18-14" tabindex="-1"></a><span class="fu">mark</span>(<span class="fu">test.cfs</span>(), <span class="fu">test.precision</span>())</span>
<span id="cb18-15"><a href="#cb18-15" tabindex="-1"></a><span class="co">#&gt; Warning: Some expressions had a GC in every iteration; so filtering is</span></span>
<span id="cb18-16"><a href="#cb18-16" tabindex="-1"></a><span class="co">#&gt; disabled.</span></span>
<span id="cb18-17"><a href="#cb18-17" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 × 6</span></span>
<span id="cb18-18"><a href="#cb18-18" tabindex="-1"></a><span class="co">#&gt;   expression            min   median `itr/sec` mem_alloc `gc/sec`</span></span>
<span id="cb18-19"><a href="#cb18-19" tabindex="-1"></a><span class="co">#&gt;   &lt;bch:expr&gt;       &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;</span></span>
<span id="cb18-20"><a href="#cb18-20" tabindex="-1"></a><span class="co">#&gt; 1 test.cfs()          751ms    751ms      1.33     477MB     13.3</span></span>
<span id="cb18-21"><a href="#cb18-21" tabindex="-1"></a><span class="co">#&gt; 2 test.precision()    943ms    943ms      1.06     810MB     19.1</span></span></code></pre></div>
<ul>
<li>Although requiring less iteration, our function takes a comparable
but slight more time and memory usage. The potential reason would be our
function calls confusion scores function that allows flexibility of
averaging methods, thus adding up the computation time.</li>
</ul>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a><span class="fu">all.equal</span>(cfs[[<span class="st">&quot;byClass&quot;</span>]][[<span class="st">&quot;Sensitivity&quot;</span>]], <span class="fu">binary_recall</span>(preds_sim, target_sim))</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a><span class="co">#&gt; [1] TRUE</span></span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>test.cfs <span class="ot">=</span> <span class="cf">function</span>(){</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a>    <span class="fu">confusionMatrix</span>(preds_sim_fac, target_sim_fac)[[<span class="st">&quot;byClass&quot;</span>]][[<span class="st">&quot;Sensitivity&quot;</span>]]</span>
<span id="cb19-6"><a href="#cb19-6" tabindex="-1"></a>  }</span>
<span id="cb19-7"><a href="#cb19-7" tabindex="-1"></a>}</span>
<span id="cb19-8"><a href="#cb19-8" tabindex="-1"></a>test.recall <span class="ot">=</span> <span class="cf">function</span>(){</span>
<span id="cb19-9"><a href="#cb19-9" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb19-10"><a href="#cb19-10" tabindex="-1"></a>    <span class="fu">binary_recall</span>(preds_sim, target_sim)</span>
<span id="cb19-11"><a href="#cb19-11" tabindex="-1"></a>  }</span>
<span id="cb19-12"><a href="#cb19-12" tabindex="-1"></a>}</span>
<span id="cb19-13"><a href="#cb19-13" tabindex="-1"></a><span class="fu">mark</span>(<span class="fu">test.cfs</span>(), <span class="fu">test.recall</span>())</span>
<span id="cb19-14"><a href="#cb19-14" tabindex="-1"></a><span class="co">#&gt; Warning: Some expressions had a GC in every iteration; so filtering is</span></span>
<span id="cb19-15"><a href="#cb19-15" tabindex="-1"></a><span class="co">#&gt; disabled.</span></span>
<span id="cb19-16"><a href="#cb19-16" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 × 6</span></span>
<span id="cb19-17"><a href="#cb19-17" tabindex="-1"></a><span class="co">#&gt;   expression         min   median `itr/sec` mem_alloc `gc/sec`</span></span>
<span id="cb19-18"><a href="#cb19-18" tabindex="-1"></a><span class="co">#&gt;   &lt;bch:expr&gt;    &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;</span></span>
<span id="cb19-19"><a href="#cb19-19" tabindex="-1"></a><span class="co">#&gt; 1 test.cfs()       1.06s    1.06s     0.941     477MB     10.4</span></span>
<span id="cb19-20"><a href="#cb19-20" tabindex="-1"></a><span class="co">#&gt; 2 test.recall() 866.03ms 866.03ms     1.15      810MB     19.6</span></span></code></pre></div>
<ul>
<li>Our computation produces accurate and robust answer, taking
comparable run-time and but requesting more memory usage.</li>
</ul>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a><span class="fu">library</span>(MLmetrics)</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a><span class="co">#&gt; Attaching package: &#39;MLmetrics&#39;</span></span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a><span class="co">#&gt; The following objects are masked from &#39;package:caret&#39;:</span></span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb20-6"><a href="#cb20-6" tabindex="-1"></a><span class="co">#&gt;     MAE, RMSE</span></span>
<span id="cb20-7"><a href="#cb20-7" tabindex="-1"></a><span class="co">#&gt; The following object is masked from &#39;package:base&#39;:</span></span>
<span id="cb20-8"><a href="#cb20-8" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb20-9"><a href="#cb20-9" tabindex="-1"></a><span class="co">#&gt;     Recall</span></span>
<span id="cb20-10"><a href="#cb20-10" tabindex="-1"></a><span class="fu">all.equal</span>(<span class="fu">F1_Score</span>(preds_sim_fac, target_sim_fac), <span class="fu">binary_f1</span>(preds_sim, target_sim))</span>
<span id="cb20-11"><a href="#cb20-11" tabindex="-1"></a><span class="co">#&gt; [1] TRUE</span></span>
<span id="cb20-12"><a href="#cb20-12" tabindex="-1"></a>test.mlmetrics <span class="ot">=</span> <span class="cf">function</span>(){</span>
<span id="cb20-13"><a href="#cb20-13" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb20-14"><a href="#cb20-14" tabindex="-1"></a>    <span class="fu">F1_Score</span>(preds_sim_fac, target_sim_fac)</span>
<span id="cb20-15"><a href="#cb20-15" tabindex="-1"></a>  }</span>
<span id="cb20-16"><a href="#cb20-16" tabindex="-1"></a>}</span>
<span id="cb20-17"><a href="#cb20-17" tabindex="-1"></a>test.recall <span class="ot">=</span> <span class="cf">function</span>(){</span>
<span id="cb20-18"><a href="#cb20-18" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb20-19"><a href="#cb20-19" tabindex="-1"></a>    <span class="fu">binary_f1</span>(preds_sim, target_sim)</span>
<span id="cb20-20"><a href="#cb20-20" tabindex="-1"></a>  }</span>
<span id="cb20-21"><a href="#cb20-21" tabindex="-1"></a>}</span>
<span id="cb20-22"><a href="#cb20-22" tabindex="-1"></a><span class="fu">mark</span>(<span class="fu">test.mlmetrics</span>(), <span class="fu">test.recall</span>())</span>
<span id="cb20-23"><a href="#cb20-23" tabindex="-1"></a><span class="co">#&gt; Warning: Some expressions had a GC in every iteration; so filtering is</span></span>
<span id="cb20-24"><a href="#cb20-24" tabindex="-1"></a><span class="co">#&gt; disabled.</span></span>
<span id="cb20-25"><a href="#cb20-25" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 × 6</span></span>
<span id="cb20-26"><a href="#cb20-26" tabindex="-1"></a><span class="co">#&gt;   expression            min   median `itr/sec` mem_alloc `gc/sec`</span></span>
<span id="cb20-27"><a href="#cb20-27" tabindex="-1"></a><span class="co">#&gt;   &lt;bch:expr&gt;       &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;</span></span>
<span id="cb20-28"><a href="#cb20-28" tabindex="-1"></a><span class="co">#&gt; 1 test.mlmetrics()     1.5s     1.5s     0.668    1.12GB     18.7</span></span>
<span id="cb20-29"><a href="#cb20-29" tabindex="-1"></a><span class="co">#&gt; 2 test.recall()     947.5ms  947.5ms     1.06   810.43MB     22.2</span></span></code></pre></div>
<p><code>MLmetrics</code> package has an equivalent function computing
on the same metrics. Our methods significantly outperforms the existing
function in terms of run-time and memory allocation.</p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
